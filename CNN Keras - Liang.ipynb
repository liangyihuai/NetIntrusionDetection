{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LDH\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras \n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path to saved model weights(as hdf5)\n",
    "resume_weights = \"model/net-cnn-best.hdf5\"\n",
    "\n",
    "# Hyper-parameters\n",
    "batch_size = 128\n",
    "num_classes = 15\n",
    "epochs = 32\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 64, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PATH = 'tmp/x_train/balanced-raw0_10000'\n",
    "temp = pd.read_csv(PATH, dtype=np.uint8, sep=',', header=None, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2048)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2048)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>2048</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1     2     3     4     5     6     7     8     9     10    ...   2039  \\\n",
       "0                                                              ...          \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "\n",
       "   2040  2041  2042  2043  2044  2045  2046  2047  2048  \n",
       "0                                                        \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 2048 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>2048</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1     2     3     4     5     6     7     8     9     10    ...   2039  \\\n",
       "0                                                              ...          \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     1     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "\n",
       "   2040  2041  2042  2043  2044  2045  2046  2047  2048  \n",
       "0                                                        \n",
       "0     0     0     1     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 2048 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2048)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_name_sorted(path):\n",
    "    fileNames = os.listdir(path)\n",
    "    li = list()\n",
    "    for name in fileNames:\n",
    "        index = int(name.rsplit('_', 1)[1])\n",
    "        li.append((index, name))\n",
    "\n",
    "    li = sorted(li, key=lambda x: x[0])\n",
    "    return [i for (_, i) in li]\n",
    "\n",
    "def get_training_data():\n",
    "    y_train_path = 'tmp/y_train/y_train_raw'\n",
    "    x_train_path = 'tmp/x_train'\n",
    "    \n",
    "    y_train0 = pd.read_csv(y_train_path, dtype=np.uint8, sep=',', header=None, index_col=0)\n",
    "    \n",
    "    x_train_files = get_file_name_sorted(x_train_path)\n",
    "    x_train0 = None\n",
    "#     for i in range(len(x_train_files)):\n",
    "    for i in range(6):\n",
    "        file_path = x_train_path+'/'+x_train_files[i]\n",
    "        print(file_path)\n",
    "        if i == 0:\n",
    "            x_train0 = pd.read_csv(file_path, dtype=np.uint8, sep=',', header=None, index_col=0)\n",
    "            print(x_train0.shape)\n",
    "        else:\n",
    "            temp = pd.read_csv(file_path, dtype=np.uint8, sep=',', header=None, index_col=0)\n",
    "            x_train0 = pd.concat([pd.DataFrame(x_train0), pd.DataFrame(temp)])\n",
    "        \n",
    "    return (x_train0, y_train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LDH\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/x_train/balanced-raw0_10000\n",
      "(10000, 2048)\n",
      "tmp/x_train/balanced-raw1000000_1010000\n",
      "tmp/x_train/balanced-raw100000_110000\n",
      "tmp/x_train/balanced-raw10000_20000\n",
      "tmp/x_train/balanced-raw1010000_1020000\n",
      "tmp/x_train/balanced-raw1020000_1030000\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train = get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 2048) (2038140, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>2048</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   2039  \\\n",
       "0     0     0     0     1     0     0     0     0     0     0  ...      0   \n",
       "1     0     0     0     1     0     0     0     0     0     0  ...      0   \n",
       "2     0     0     0     1     0     0     0     0     0     0  ...      0   \n",
       "3     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "4     0     0     0     1     0     0     0     0     0     0  ...      0   \n",
       "\n",
       "   2040  2041  2042  2043  2044  2045  2046  2047  2048  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>2048</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...   2039  \\\n",
       "9995     0     0     0     1     0     0     0     0     0     0  ...      0   \n",
       "9996     0     0     0     1     0     0     0     0     0     0  ...      0   \n",
       "9997     0     0     0     1     0     0     0     0     0     0  ...      0   \n",
       "9998     0     0     0     1     0     0     0     0     0     0  ...      0   \n",
       "9999     0     0     0     1     0     0     0     0     0     0  ...      0   \n",
       "\n",
       "      2040  2041  2042  2043  2044  2045  2046  2047  2048  \n",
       "9995     0     0     0     0     0     0     0     0     0  \n",
       "9996     0     0     0     0     0     0     0     0     0  \n",
       "9997     0     0     0     0     0     0     0     0     0  \n",
       "9998     0     0     0     0     0     0     0     0     0  \n",
       "9999     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2038140, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_val_data():\n",
    "    x_val_path = \"tmp/X_val/X_val_raw\"\n",
    "    y_val_path = \"tmp/y_val/y_val_raw\"\n",
    "    \n",
    "    x_val = pd.read_csv(x_val_path, dtype=np.uint8, sep=',', header=None, index_col=0)\n",
    "    y_val = pd.read_csv(y_val_path, dtype=np.uint8, sep=',', header=None, index_col=0)\n",
    "    return (x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val, y_val = get_val_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226460, 2048) (226460, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = x_val[:60000], y_val[:60000]\n",
    "x_test, y_test = x_val[60000:80000], y_val[60000:80000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    x_test_path = 'tmp/X_test/X_test_raw'\n",
    "    y_test_path = \"tmp/y_test/y_test_raw\"\n",
    "   \n",
    "    x_test = pd.read_csv(x_test_path, dtype=np.uint8, sep=',', header=None, index_col=0).reset_index() \n",
    "    y_test = pd.read_csv(y_test_path, dtype=np.uint8, sep=',', header=None, index_col=0).reset_index() \n",
    "    \n",
    "    return (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 64, 32, 1)\n",
      "60000 train samples\n",
      "20000 test samples\n",
      "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14] [ 0  1  2  3  4  5  6  7 10 11 12 14]\n",
      "(60000, 15) (20000, 15)\n"
     ]
    }
   ],
   "source": [
    "# MNIST handwritten image classification\n",
    "# the data, shuffled and split between train and test sets\n",
    "\n",
    "# Reshape strategy according to backend\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.values.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.values.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    # 1 x 28 x 28 [number_of_channels (colors) x height x weight]\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.values.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.values.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    # 28 x 28 x 1 [height x weight x number_of_channels (colors)]\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "# Reshape, type, normalized, print\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# x_train /= 255\n",
    "# x_test /= 255\n",
    "\n",
    "# Dataset info\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(np.unique(y_train), np.unique(y_test))\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 15)\n",
      "(20000, 15)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildModel():\n",
    "    # MODEL\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', \n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, (3, 2), activation='relu'))\n",
    "   \n",
    "    model.add(Conv2D(256, (3, 2), activation='relu'))\n",
    "  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "   \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation=Activation(tf.nn.softmax)))\n",
    "    # CEE, Adam\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "            optimizer=keras.optimizers.Adam(),\n",
    "            metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20191215_21_25_59\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now().strftime('%Y%m%d_%H_%M_%S'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(model, is_resume_weight = False, resume_weights_path=''):\n",
    "    # If exists a best model, load its weights!\n",
    "    if is_resume_weight:\n",
    "        if os.path.isfile(resume_weights_path):\n",
    "            print (\"Resumed model's weights from {}\".format(resume_weights))\n",
    "            # load weights\n",
    "            model.load_weights(resume_weights_path)\n",
    "            return \n",
    "\n",
    "\n",
    "    # Checkpoint In the /output folder\n",
    "    filepath = \"output/net-cnn-best.hdf5\"\n",
    "    os.makedirs('output', exist_ok=True)\n",
    "\n",
    "    # Keep only a single checkpoint, the best over test accuracy.\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"logs\\{}\".format(str(datetime.datetime.now().strftime('%Y%m%d_%H_%M_%S'))), histogram_freq=1)\n",
    "\n",
    "    # Train\n",
    "    hist = model.fit(x_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_data=(x_test, y_test), \n",
    "                callbacks=[tensorboard_callback, checkpoint])\n",
    "    print(hist.history.keys())\n",
    "    model.save_weights(filepath, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 13, 128)       49280     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 26, 12, 256)       196864    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 6, 256)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 19968)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               5112064   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                3855      \n",
      "=================================================================\n",
      "Total params: 5,380,879\n",
      "Trainable params: 5,380,879\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LDH\\Anaconda3\\lib\\site-packages\\keras\\activations.py:197: UserWarning: Do not pass a layer instance (such as Activation) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session() # It is important if to create the model twice\n",
    "tf.summary.FileWriterCache.clear()\n",
    "\n",
    "model = buildModel()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6690163543262387021\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9290641572\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 9573063997996879670\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0\"\n",
      "]\n",
      "2.2.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/gpu:0']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(keras.__version__)\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 20000 samples\n",
      "Epoch 1/32\n",
      "60000/60000 [==============================] - 19s 314us/step - loss: 0.2161 - acc: 0.9335 - val_loss: 0.0991 - val_acc: 0.9651\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.96515, saving model to output/net-cnn-best.hdf5\n",
      "Epoch 2/32\n",
      "60000/60000 [==============================] - 18s 294us/step - loss: 0.1021 - acc: 0.9633 - val_loss: 0.0825 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.96515 to 0.96840, saving model to output/net-cnn-best.hdf5\n",
      "Epoch 3/32\n",
      "60000/60000 [==============================] - 18s 295us/step - loss: 0.0898 - acc: 0.9666 - val_loss: 0.0786 - val_acc: 0.9694\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.96840 to 0.96940, saving model to output/net-cnn-best.hdf5\n",
      "Epoch 4/32\n",
      "60000/60000 [==============================] - 18s 294us/step - loss: 0.0850 - acc: 0.9675 - val_loss: 0.0745 - val_acc: 0.9686\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.96940\n",
      "Epoch 5/32\n",
      "60000/60000 [==============================] - 17s 288us/step - loss: 0.0809 - acc: 0.9680 - val_loss: 0.0711 - val_acc: 0.9694\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.96940\n",
      "Epoch 6/32\n",
      "60000/60000 [==============================] - 17s 287us/step - loss: 0.0760 - acc: 0.9701 - val_loss: 0.0690 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.96940 to 0.96985, saving model to output/net-cnn-best.hdf5\n",
      "Epoch 7/32\n",
      "60000/60000 [==============================] - 18s 293us/step - loss: 0.0739 - acc: 0.9702 - val_loss: 0.0688 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.96985 to 0.97120, saving model to output/net-cnn-best.hdf5\n",
      "Epoch 8/32\n",
      "60000/60000 [==============================] - 17s 287us/step - loss: 0.0717 - acc: 0.9711 - val_loss: 0.0677 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.97120 to 0.97160, saving model to output/net-cnn-best.hdf5\n",
      "Epoch 9/32\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 0.0711 - acc: 0.9716 - val_loss: 0.0652 - val_acc: 0.9717\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.97160 to 0.97170, saving model to output/net-cnn-best.hdf5\n",
      "Epoch 10/32\n",
      "60000/60000 [==============================] - 18s 293us/step - loss: 0.0696 - acc: 0.9717 - val_loss: 0.0669 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.97170\n",
      "Epoch 11/32\n",
      "60000/60000 [==============================] - 18s 294us/step - loss: 0.0695 - acc: 0.9720 - val_loss: 0.0684 - val_acc: 0.9714\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.97170\n",
      "Epoch 12/32\n",
      "60000/60000 [==============================] - 18s 293us/step - loss: 0.0688 - acc: 0.9722 - val_loss: 0.0654 - val_acc: 0.9719\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.97170 to 0.97190, saving model to output/net-cnn-best.hdf5\n",
      "Epoch 13/32\n",
      "60000/60000 [==============================] - 18s 293us/step - loss: 0.0681 - acc: 0.9723 - val_loss: 0.0665 - val_acc: 0.9722\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.97190 to 0.97220, saving model to output/net-cnn-best.hdf5\n",
      "Epoch 14/32\n",
      "60000/60000 [==============================] - 18s 294us/step - loss: 0.0675 - acc: 0.9723 - val_loss: 0.0645 - val_acc: 0.9722\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.97220 to 0.97225, saving model to output/net-cnn-best.hdf5\n",
      "Epoch 15/32\n",
      "60000/60000 [==============================] - 18s 293us/step - loss: 0.0673 - acc: 0.9723 - val_loss: 0.0641 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.97225\n",
      "Epoch 16/32\n",
      "60000/60000 [==============================] - 18s 293us/step - loss: 0.0673 - acc: 0.9725 - val_loss: 0.0662 - val_acc: 0.9719\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.97225\n",
      "Epoch 17/32\n",
      "60000/60000 [==============================] - 17s 286us/step - loss: 0.0662 - acc: 0.9727 - val_loss: 0.0642 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.97225\n",
      "Epoch 18/32\n",
      "60000/60000 [==============================] - 17s 286us/step - loss: 0.0661 - acc: 0.9729 - val_loss: 0.0644 - val_acc: 0.9724\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.97225 to 0.97235, saving model to output/net-cnn-best.hdf5\n",
      "Epoch 19/32\n",
      "60000/60000 [==============================] - 18s 296us/step - loss: 0.0663 - acc: 0.9726 - val_loss: 0.0644 - val_acc: 0.9721\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.97235\n",
      "Epoch 20/32\n",
      "60000/60000 [==============================] - 18s 295us/step - loss: 0.0660 - acc: 0.9729 - val_loss: 0.0659 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.97235\n",
      "Epoch 21/32\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: 0.0654 - acc: 0.9728 - val_loss: 0.0651 - val_acc: 0.9725\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.97235 to 0.97250, saving model to output/net-cnn-best.hdf5\n",
      "Epoch 22/32\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: 0.0656 - acc: 0.9726 - val_loss: 0.0642 - val_acc: 0.9722\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.97250\n",
      "Epoch 23/32\n",
      "60000/60000 [==============================] - 18s 295us/step - loss: 0.0645 - acc: 0.9731 - val_loss: 0.0647 - val_acc: 0.9721\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.97250\n",
      "Epoch 24/32\n",
      "60000/60000 [==============================] - 18s 294us/step - loss: 0.0646 - acc: 0.9729 - val_loss: 0.0653 - val_acc: 0.9722\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.97250\n",
      "Epoch 25/32\n",
      "60000/60000 [==============================] - 18s 293us/step - loss: 0.0651 - acc: 0.9729 - val_loss: 0.0635 - val_acc: 0.9724\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.97250\n",
      "Epoch 26/32\n",
      "60000/60000 [==============================] - 18s 294us/step - loss: 0.0646 - acc: 0.9731 - val_loss: 0.0640 - val_acc: 0.9724\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.97250\n",
      "Epoch 27/32\n",
      "60000/60000 [==============================] - 18s 295us/step - loss: 0.0644 - acc: 0.9730 - val_loss: 0.0635 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.97250 to 0.97265, saving model to output/net-cnn-best.hdf5\n",
      "Epoch 28/32\n",
      "60000/60000 [==============================] - 18s 294us/step - loss: 0.0637 - acc: 0.9731 - val_loss: 0.0642 - val_acc: 0.9728\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.97265 to 0.97275, saving model to output/net-cnn-best.hdf5\n",
      "Epoch 29/32\n",
      "60000/60000 [==============================] - 17s 290us/step - loss: 0.0636 - acc: 0.9732 - val_loss: 0.0637 - val_acc: 0.9728\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.97275 to 0.97280, saving model to output/net-cnn-best.hdf5\n",
      "Epoch 30/32\n",
      "60000/60000 [==============================] - 17s 285us/step - loss: 0.0637 - acc: 0.9731 - val_loss: 0.0643 - val_acc: 0.9724\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.97280\n",
      "Epoch 31/32\n",
      "60000/60000 [==============================] - 17s 286us/step - loss: 0.0641 - acc: 0.9730 - val_loss: 0.0631 - val_acc: 0.9728\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.97280\n",
      "Epoch 32/32\n",
      "60000/60000 [==============================] - 17s 285us/step - loss: 0.0645 - acc: 0.9733 - val_loss: 0.0636 - val_acc: 0.9728\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.97280\n",
      "dict_keys(['val_loss', 'acc', 'loss', 'val_acc'])\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146460, 2048)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val[80000:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_eval = np.reshape(x_val.values[80000:], (146460, 64, 32, 1))\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_eval = keras.utils.to_categorical(y_val[80000:], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146460/146460 [==============================] - 20s 140us/step\n",
      "Test loss: 0.0649811231706647\n",
      "Test accuracy: 0.9739792434794483\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "score = model.evaluate(x_eval, y_eval, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LDH\\Anaconda3\\lib\\site-packages\\keras\\activations.py:197: UserWarning: Do not pass a layer instance (such as Activation) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumed model's weights from model/net-cnn-best.hdf5\n",
      "20000/20000 [==============================] - 3s 136us/step\n",
      "Test loss: 0.06358545612062007\n",
      "Test accuracy: 0.9728\n"
     ]
    }
   ],
   "source": [
    "# test to load weights\n",
    "model1 = buildModel()\n",
    "train(model1, True, 'output/net-cnn-best.hdf5')\n",
    "# Eval\n",
    "score = model1.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "val_losses = [0.0991, 0.0825, 0.0786, 0.0745, 0.0711, 0.0690, 0.0688, 0.0677, 0.0652, 0.0669,0.0684 ,\n",
    "              0.0654 ,0.0665, 0.0645, 0.0641,  0.0662, 0.0642, 0.0644, 0.0644, 0.0659, 0.0651, 0.0642, \n",
    "              0.0647, 0.0653, 0.0635, 0.0640, 0.0635, 0.0642 , 0.0637, 0.0643 , 0.0631, 0.0636,  ]\n",
    "\n",
    "val_accs = [0.9651 ,0.9684,0.9694,0.9686,0.9694,0.9698,0.9712,0.9716,\n",
    "0.9717,0.9708,0.9714,0.9719,0.9722,0.9722,0.9720,0.9719,0.9718,0.9724,\n",
    "0.9721,0.9710,0.9725,0.9722,0.9721,0.9722,0.9724,0.9724,0.9727,0.9728,\n",
    "0.9728,0.9724,0.9728,0.9728]\n",
    "\n",
    "train_losses = [0.2161 , 0.1021, 0.0898, 0.0850, 0.0809, 0.0760, 0.0739, 0.0717,\n",
    " 0.0711, 0.0696, 0.0695, 0.0688, 0.0681, 0.0675, 0.0673, 0.0673, 0.0662,\n",
    " 0.0661, 0.0663, 0.0660, 0.0654, 0.0656, 0.0645, 0.0646, 0.0651, 0.0646, 0.0644,\n",
    " 0.0637, 0.0636, 0.0637, 0.0641, 0.0645,]\n",
    "\n",
    "training_accs = [0.9335 , 0.9633, 0.9666, 0.9675,\n",
    " 0.9680,0.9701,0.9702,0.9711,0.9716,0.9717, 0.9720, 0.9722, 0.9723, 0.9723, 0.9723, 0.9725,\n",
    " 0.9727, 0.9729, 0.9726, 0.9729, 0.9728, 0.9726, 0.9731, 0.9729, 0.9729, 0.9731, 0.9730, 0.9731, 0.9732,\n",
    " 0.9731, 0.9730, 0.9733\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19358304128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.title('losses')\n",
    "steps = [i for i in range(32)]\n",
    "plt.plot(steps, val_losses, color='blue', label='validation loss')\n",
    "plt.plot(steps, train_losses,  color='red', label='training loss')\n",
    "plt.legend() # æ˜¾ç¤ºå›¾ä¾‹\n",
    "\n",
    "plt.xlabel('iteration times')\n",
    "plt.ylabel('loss value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4VeW99vHvTZgxQICITAK2yCACQgQ9omJRi9qi4IBY\nD+iBUn0V9ZxaS2mr9PT0PRyrVq1UX1QstihSLRU9DlWEolUrQQMyCiKWMEYIJExCwu/9Y60ddpKd\nZGfYGX+f61pX9pqflQ3rznqetZ4lM8M555yrqEY1XQDnnHN1mweJc865SvEgcc45VykeJM455yrF\ng8Q551yleJA455yrFA8S55xzleJB4lwpJC2VlC2pWU2XxbnayoPEuRJI6gGcDxgwuhr327i69uVc\nVfAgca5kE4APgd8DEyMTJbWQ9KCkLyXtl/SepBbhvOGS3pe0T9JWSTeF05dKmhy1jZskvRc1bpJu\nk7QR2BhOeyTcRo6kFZLOj1o+SdJ0SZ9Lyg3nd5M0S9KD0QchaZGkf0/EL8g58CBxrjQTgHnh8G1J\nHcPpDwBDgH8B2gH3AMcldQdeB34LpAKDgIxy7O8qYBjQLxxfHm6jHfAc8CdJzcN5/wGMBy4HWgP/\nBhwC5gLjJTUCkNQBuDhc37mE8CBxLgZJw4HuwAIzWwF8DtwQnqD/DbjTzLaZWb6ZvW9mXwM3AG+b\n2fNmdszM9phZeYLkv81sr5kdBjCzP4bbyDOzB4FmQO9w2cnAz8xsgwVWhst+BOwHRobLXQ8sNbNd\nlfyVOFciDxLnYpsI/NXMvgrHnwundQCaEwRLUd1KmB6vrdEjku6WtC6sPtsHtAn3X9a+5gI3hp9v\nBP5QiTI5VyZv1HOuiLC94zogSdLOcHIzoC3QCTgCfANYWWTVrcDQEjZ7EGgZNX5KjGUKuuIO20Pu\nIbiyWGNmxyVlA4ra1zeA1TG280dgtaSBQF/gLyWUybkq4VckzhV3FZBP0FYxKBz6Au8StJvMAR6S\n1Dls9D43vD14HnCxpOskNZbUXtKgcJsZwFhJLSV9E5hURhmSgTwgC2gs6V6CtpCIp4BfSuqlwABJ\n7QHMLJOgfeUPwEuRqjLnEsWDxLniJgLPmNk/zWxnZAAeA74HTAM+JThZ7wX+B2hkZv8kaPz+YTg9\nAxgYbvM3wFFgF0HV07wyyvAm8AbwGfAlwVVQdNXXQ8AC4K9ADvA00CJq/lzgTLxay1UD+YutnKt/\nJF1AUMXV3fw/uUswvyJxrp6R1AS4E3jKQ8RVBw8S5+oRSX2BfQQ3BTxcw8VxDYRXbTnnnKuUhF6R\nSBolaYOkTZKmxZifImmhpFWSPpLUP5zeW1JG1JAj6a5w3gxJ26LmXZ7IY3DOOVe6hF2RSEoiuOPk\nEiByO+J4M1sbtcyvgQNm9gtJfYBZZjYyxna2AcPM7EtJM8J1Hoi3LB06dLAePXpU9pCcc65BWbFi\nxVdmllrWcol8IHEosMnMNgNImg9cCayNWqYfMBPAzNZL6iGpY5HuHEYCn5vZlxUtSI8ePUhPT6/o\n6s451yBJiuu8m8iqrS4Uvu89M5wWbSUwFkDSUIK+jboWWeZ64Pki06aG1WFzJKXE2rmkKZLSJaVn\nZWVV9Bicc86Voabv2poJtJWUAUwFPiF4ohgASU0J3gPxp6h1HgdOI3jaeAdQqMvsCDObbWZpZpaW\nmlrmlZlzzrkKSmTV1jaCjuUiuobTCphZDnAzgCQBXwCboxa5DPg4uqor+rOkJ4FXq7zkzjnn4pbI\nK5LlQC9JPcMri+uBRdELSGobzoOgW+xlYbhEjKdItZakTlGjY4jdaZ1zzrlqkrArEjPLk3Q7QZ9B\nScAcM1sj6ZZw/hMEHeHNlWTAGqI6spPUiuCOrx8U2fT9YUd4BmyJMd8551w1ahAPJKalpZnfteWc\nc+UjaYWZpZW1XE03tjvnnKvj/MVWzjmXaJGaH6n05arC/v2wYQN89lnwc9IkSPAD2R4kzrnq989/\nwtKlsHUrdOoEnTufGNq3r7oTbl4e7N4N27cHw44dsGsXNGkCycmlDy1awMGDkJsbezhwoOR5sQYz\nOOmksvebnFz2ci1bwrZtQVBEh8aGDcHxRSQlwbnnepA41+CZBX9lRk6GkUGC00+H3r3hG9+AZs3K\nt90DB06cgDZtCrZX1gmudWto2rTsbRe1bRssWRIMS5fC5s0lL9ukSfFwSU4uO1zMYM+eICwiv6Nd\nu+D48fKXtxwsKpTspMjvqg107oolJ0M4rVGS0MEY4fPVV4XHv/66/GXo0AE7vTd22RVYr97B59N7\nw2mn0bhl04S3YXiQOFeTcnOLB0T0EDkpHi7jbbmNGgV/dfbuXXw4cuTEX6vRw/btFStzSkrhk3zR\nk37nzsFfwu++eyI4Nm48se6FF8Idd8BFF0GvXsHJvujxRob162Hx4uDKIB7t2p0oz6BBxcvVuTOc\nfHJwpVLkhG45uezPzGXXplz2bMklZ/dhcvNasi8/mey8ZPYeS+arr5PJOpLM7sPJ7DwYDEeONQve\nh7m39KIlJ8PgwTBkCKRdDGlpQf43KnqWP3asULnysnP5cnUuX6zKZdv6XHZ/nsu+7QfZln8KG+jN\nBnqT/VU7+Ap4v/h+X38dRo2K79dXUX7XlnOJcOhQ7BNj0eHAgeLrtmoFXbqUfJLu3Bk7pROWl0+j\nTZ8VDofPPguGQ4dil6tt29hh841vBCf/UqpvDu7M5eMl+2l3dCcn52+nzcHtNMnajnbsCE7MsbRu\nDRdcEITGRRfBgAHBfhIgLy84B8ez3BdfxM7WnKin2Bo3hjZt4qsBi6cmbvt2WLECMjKCbIdg+0OG\nhOGSFvw8dAjS04MhsnzkIqVNm2C5wYODrzIe48YFX29FxHvXlgeJqz+OHw+qgMqoxz6+P5e8I3Gc\ncYAmjeM4SeTnQ1ZW4YDYv7/4cs2bx/4LueiQnBxzN0eOwDvvwKJF8MorQY3IN795IgsitVy9ex2n\n/ZFtJ4KlWbMTC3XoUKH2h48+guuugy+LdOHXujX0Of04Q3rsYdDJ2+nTejs9m23n5JMO0fTCc9FZ\ng4IzciUcPRoca0kXa5EhK+tEm3Z5dOsW9buLGk49NcbVQhU4dgzWri0cFitXBscZLTm5cMhErmCq\no70+woMkigdJHWcG2dml/2UfObOU9JdxlHwa8TXxtydIZQyNBKmpKFYoRF9RtG1b7rPA7t3wv/8b\nhMdf/xr8tXrSSfDtb8Npp51o4vj888J/jbdvfyJcRo+Gq66q2AnIDB57DH74w+AQ5s+HU04p3r67\nYUPQbh4tKankNuPI9CZNym6jLnqCjXwnHTsW/1W3aFH2MTVqFIRE795BzVqrVuX/vVS1o0dh9eog\nVFq0gLPPDsqWiCArDw+SKB4kdcSRI0FdetEz1IYNsG9f8eXDunrr3Jn9rTqz+XBnPstOZcueZD7f\nncy23GRyCYbDScm075FMlz7J9OzbnA6piqvtdu/e4n/5xioKBDfSxHPDTVk36ezdC6++GoTHhx8G\n5ejWDb773SAURowo3q5etLom8itcuzb4S/288+DBB2HYsPi/jpwcmDwZ/vQn+M53YO7coAmiJAcP\nBm32GzYEZYnnRqa8vPh+P+3anajtizRzVPJCx8XBgySKB0nVOXo0uDGmrBPEsZzDXDpkDxcOzkUH\nSllw374TZ58vvyxcN9Gly4k/q3v1gq5dg+Do1JlNBzvxzgctWLo0aMvduTNY5eSToU+f4tUUPXoE\nf/1WhUOHCofLjh3Fa9RKGuJtM4agKiMSHgMHVuyKIi8P5syBn/88uLq5/nr4v/8XevYsfb2VK+Ga\na4JA+O//Dq5IavqvY1f9PEiieJBUzLFjweV2pB43PR1WrYrdoNmKA5zH37mIJYxgKWmk0/jEGwFi\nk4JK9tNOK37mP/304M/00OefB4ERuYM0csNRp04n2nFHjKj+OuTyOn689EcTcnODq41LLw1ytKrk\n5sL99wdXJfn5cOedMH168QZbM3j6abj99qB67IUXYPjwqiuHq1s8SKJ4kJQtPx/WrCneAFj0bpEh\nQ4K/Zts2PcSpme/TecMSOny6hFbrlqO8PKxxYxg2jOPDL+Qfu7rzl7eTWZuZTPMOyXz3hmTGTkwm\nuXPUQ1UlnPXz8uD99080LH/2WTC9Y8cgMCLBcfrptTs4apvMTPjpT+EPfwiqi+67D265JbhaO3gQ\nbr01mHfxxTBvXnCF5xqueIMEM6v3w5AhQ8yVbPVqs4EDzYK/R82Sk81GjDC7+26z+fPNNm0yO37c\nzPbuNZs502z4cLMmTYKFk5LMzjnH7Cc/MXvzTbMDBwpt+/hxs9dfN/vWt05s+4c/NPvnP4uXY/9+\nswULzG680axdu2D5Jk3Mvv1ts9/+1mzt2rAcrtJWrDC76KLgd9yrl9ns2Wb9+plJZjNmmOXl1XQJ\nXW0ApFsc59gaP8lXx+BBEtvx42aPPmrWvLlZampwMtmwwSw/v8iCX3xhdscdZq1aBf9k0tLM7rkn\nSIicnLj3t2KF2fjxQfY0bhwExpIlQUhceumJbGrXzmzCBLM//SkIF5cYx4+bvfKKWZ8+we89NdXs\nrbdqulSuNok3SLxqq4HauRP+7d+Cp14vvzxokO3YschCK1bAr38d3LbTqBHccAPcfTeceWal9r1l\nCzzyCDz55InG5969TzQsn3uu35FTnfLygirEc88N2pyci6gVVVvAKGADsAmYFmN+CrAQWAV8BPQP\np/cGMqKGHOCucF474C1gY/gzpaxy+BVJYYsWmXXoEFyJPPZYkeqi/Hyz//3foG4LzFq3NvvRj8y2\nbq3ycuzda/b882br11f5pp1zVYA4r0gSdkOfpCRgFsF71/sB4yX1K7LYdCDDzAYAE4BHAMxsg5kN\nMrNBwBDgUBg4ANOAxWbWC1gcjrs4HDwYNKyOHh3cSbtiBdz2fwwdORzcG/rMM8HVxhVXBLfkPvBA\n8JTZ/fcHK1SxlJTgdtTevat80865apTICoShwCYz2wwgaT5wJbA2apl+wEwAM1svqYekjmYW1Q8y\nI4HPzSzSOcOVwIjw81xgKfDjRB1Enffxx/Db35L95X7W/iOXmw7lMqN9Lh2/ykXnhfeb5kfdpjtg\nQHDbzrhxVffghXOuXktkkHQBojtNyASKPle7EhgLvCtpKNAd6ApEB8n1wPNR4x3NbEf4eSdQtGbf\nRaxciY0cyddHjG1HutGsaTI909rQ/tQusR8f7tcvuK/W76d1zpVDTTdpzgQekZQBfAp8AieeYpPU\nFBgN/CTWymZmkmLeLSBpCjAF4NRTT63iYtdOeXknOoPbuvgzpi64lEN5J3Ee7zHs2u488UTpXVw4\n51xFJDJItgHdosa7htMKmFkOcDOAJAFfANFvvLkM+LhIVdcuSZ3MbIekTsDuWDs3s9nAbAju2qrk\nsVSJgweDp5ar4o4ks+BVDcuXn3iIMCMjeG1FN/7J33UxamzMu/ltfnd1dy6/3C80nHOJkcjec5YD\nvST1DK8srgcWRS8gqW04D2AysCwMl4jxFK7WItzGxPDzRODlKi95Fdu+PXiPT/v2Qa+jP/958KbR\nisjJgd/9LnhnT79+MHFicOtu48ZBQ/qLs3axqfvFdG2dQ8pHf+XHc3pzxRUeIs65BIrn1q6KDsDl\nwGfA58BPw2m3ALeEn88N528A/kzUrbxAK2AP0KbINtsT3K21EXgbaFdWOWrq9t8dO8zuuiu4zTYp\nyeymm8yuuCJ4erhRo+DzK6/E9xRxerrZ5Mknngk86yyz3/3ObM2aqPX37jUbMMCsZUuzv/89ocfm\nnKv/8Cfbay5Idu0KugFp0eJEgGzadGL+li1mP/2p2SmnBN9At25m//mfZtu2Fd5Obq7Zk0+aDRkS\nLNeypdmkSWYffRSjq5Dc3KCrkqZNzf7614Qfo3Ou/os3SPzJ9ir01VfBg+CPPRa8WuN73wuqsXr1\nir38sWPBE8X/7//BW28FLwIaPRrGjw96uv3DH4K7c/v3D6qtbrwx6DyxmCNHgmc//va34Cn0MWMS\neZjOuQYi3ifba/qurXph797g2b1HHw3eVTF+PNx7b9kP2jVpAldfHQybNgVdhsyZAwsXBo3y110X\nBMi555bSxnHsWPDMxzvvBG8e8hBxzlUzvyKppGPHgu7VP/00OPHfe2/QCF5RX38Nf/978CKj9u3L\nWPj4cZgwIejv+7HH4LbbKr5j55wrwq9IqsljjwUve/rTn4I3ylVWs2bwrW/FseCxY8HbiebNg1/9\nykPEOVdjPEgqYceO4MVAl10WVE8lVF5e0DlW5DWB770XPJhyzz3wk5jPazrnXLXwIKmEH/0oqIp6\n9NEEPKeRnx88YRh5t+y77wYt7wBnnAE33RS8j/W73/WHRJxzNcqDpIKWLQtqlX72M/jmN6too2aw\neHHwxOE778D+/cH03r2DW8Ai75f1958652oRD5IKOHYsaJLo3r2KapWOHYMFC4JbvzIygjdMXXfd\nieDwtw0552oxD5IKmDULVq+GP/8ZWrasxIZycuCpp+Dhh4P3fvTtC08/HVx9NGtWZeV1zrlE8iAp\np507gwb2UaPgqqsquJFt24KGlSeeCMLkwgvh8ceDVvtGiez+zDnnqp4HSTndc0/wIHmFGtjXrYP/\n+R947rmgMf2aa4J3oJ99dkLK6pxz1cGDpBzefTfotuSnPy2525MSZWbC0KHBQ4S33AL//u/Qs2dC\nyumcc9XJgyROeXlBA/upp8L06RXYwA9/GGxk9Wr4xjeqvHzOOVdTPEjiNGtW0A3KSy9VoIF98eLg\nrqxf/MJDxDlX73hfW3HYuTN4lOPcc+H118vZNnL0aNBx1tGjsGYNNG9e4XI451x18r62qtCPfxy8\nwrZCDeyPPBK8E/fVVz1EnHP1UkLvNZU0StIGSZskTYsxP0XSQkmrJH0kqX/UvLaSXpS0XtI6SeeG\n02dI2iYpIxwuT+QxvPcePPtscHPV6aeXc+XMzKA667vfDd4X4pxz9VDCrkgkJQGzgEuATGC5pEVm\ntjZqselAhpmNkdQnXH5kOO8R4A0zuyZ8r3t0y8RvzOyBRJU9ItLA3q1bcKdWud19d7CRhx+u8rI5\n51xtkcgrkqHAJjPbbGZHgfnAlUWW6Qe8A2Bm64EekjpKagNcADwdzjtqZvsSWNaYHn886CL+N7+B\nVq3KufKSJfDCC0EfKqedlpDyOedcbZDIIOkCbI0azwynRVsJjAWQNBToDnQFegJZwDOSPpH0lKTo\nU/nUsDpsjqSUWDuXNEVSuqT0rKysCh1A06ZB9/Bjx5ZzxUhnXD17Bk8wOudcPVbT/XHMBNpKygCm\nAp8A+QRVboOBx83sLOAgEGljeRw4DRgE7AAejLVhM5ttZmlmlpaamlqhwv3gB/DiixVsYF+3LvjZ\nokWF9u2cc3VFIu/a2gZ0ixrvGk4rYGY5wM0AkgR8AWwmaA/JNLN/hIu+SBgkZrYrsr6kJ4FXE1T+\nitm+PWhg/853gkZ255yr5xJ5RbIc6CWpZ9hYfj2wKHqB8M6spuHoZGCZmeWY2U5gq6Te4byRwNpw\nneg+1ccAqxN4DOV3991B1dYjj9R0SZxzrlok7IrEzPIk3Q68CSQBc8xsjaRbwvlPAH2BuZIMWANM\nitrEVGBeGDSbCa9cgPslDQIM2AL8IFHHUG5LlsDzzwfdA3sDu3OugfAn26vKsWMwaFDw5OKaNd42\n4pyr8/zJ9ur26KOwdi28/LKHiHOuQanpu7bqh+3bYcaM4Ol1b2B3zjUwHiRV4d57TzSwl/teYeec\nq9s8SKrCihUwcqR3Ee+ca5A8SKpCdja0b1/TpXDOuRrhQVIVsrMhJWZPLc45V+95kFRWfj7k5HiQ\nOOcaLA+SytoXdkrsQeKca6A8SCorOzv46UHinGugPEgqy4PEOdfAeZBUlgeJc66B8yCpLA8S51wD\n50FSWR4kzrkGzoOksjxInHMNnAdJZWVnQ7Nm3uOvc67B8iCpLH+q3TnXwCU0SCSNkrRB0iZJ02LM\nT5G0UNIqSR9J6h81r62kFyWtl7RO0rnh9HaS3pK0MfxZs2dxDxLnXAOXsCCRlATMAi4D+gHjJfUr\nsth0IMPMBgATgOgXnT8CvGFmfYCBwLpw+jRgsZn1AhaH4zXHg8Q518Al8opkKLDJzDab2VFgPnBl\nkWX6Ae8AmNl6oIekjpLaABcAT4fzjppZ2BcJVwJzw89zgasSeAxl8yBxzjVwiQySLsDWqPHMcFq0\nlcBYAElDge5AV6AnkAU8I+kTSU9JahWu09HMdoSfdwIdY+1c0hRJ6ZLSs7KyquSAYvIgcc41cDXd\n2D4TaCspA5gKfALkE7xLfjDwuJmdBRwkRhWWmRlgsTZsZrPNLM3M0lJTUxNVfg8S51yD1ziB294G\ndIsa7xpOK2BmOcDNAJIEfAFsBloCmWb2j3DRFzkRJLskdTKzHZI6AbsTdwhlyM+H/fs9SJxzDVoi\nr0iWA70k9ZTUFLgeWBS9QHhnVtNwdDKwzMxyzGwnsFVS73DeSGBt+HkRMDH8PBF4OYHHULr9+4Of\nHiTOuQYsYVckZpYn6XbgTSAJmGNmayTdEs5/AugLzJVkwBpgUtQmpgLzwqDZTHjlQlAdtkDSJOBL\n4LpEHUOZ/F0kzjmX0KotzOw14LUi056I+vwBcHoJ62YAaTGm7yG4Qql53j2Kc87VeGN73eZB4pxz\nHiSV4kHinHMeJJXiQeKccx4kleJB4pxzHiSVkp0NTZt6F/LOuQbNg6QyIk+1SzVdEuecqzEeJJXh\n3aM451x8QSLpz5KukOTBE82DxDnn4r4i+R1wA7BR0syorksaNg8S55yLL0jM7G0z+x5Bj7xbgLcl\nvS/pZklNElnAWs2DxDnn4m8jkdQeuImgc8VPCN5gOBh4KyElqws8SJxzLr6+tiQtBHoDfwC+G/Vi\nqRckpSeqcLXa8eNBp41t29Z0SZxzrkbF22njo2a2JNYMMyvWsWKDkJMDZn5F4pxr8OKt2uonqeBP\nb0kpkv5PgspUN/hT7c45B8QfJN83s32RETPLBr6fmCLVER4kzjkHxB8kSeGrcAGQlAQ0LWX5+s+D\nxDnngPiD5A2ChvWRkkYCz4fTSiVplKQNkjZJmhZjfoqkhZJWSfpIUv+oeVskfSopI7pBX9IMSdvC\n6RmSLo/zGKqWB4lzzgHxN7b/GPgBcGs4/hbwVGkrhFcts4BLgExguaRFZrY2arHpQIaZjZHUJ1w+\n+u2HF5nZVzE2/xszeyDOsieGB4lzzgFxBomZHQceD4d4DQU2mdlmAEnzgSuB6CDpR/AOdsxsvaQe\nkjqa2a5y7KdmeJA45xwQf19bvSS9KGmtpM2RoYzVugBbo8Yzw2nRVgJjw30MBboDXcN5RvAE/QpJ\nU4qsNzWsDpsjKeaZXNIUSemS0rOysuI4ynLKzobGjaFVq6rftnPO1SHxtpE8Q3A1kgdcBDwL/LEK\n9j8TaCspA5hK8MR8fjhvuJkNAi4DbpN0QTj9ceA0YBCwA3gw1obNbLaZpZlZWmpqahUUtQjvQt45\n54D4g6SFmS0GZGZfmtkM4Ioy1tkGdIsa7xpOK2BmOWZ2cxgYE4BUYHM4b1v4czewkKCqDDPbZWb5\nYXXbk5Hp1c67R3HOOSD+IPk67EJ+o6TbJY0BTipjneVAL0k9JTUFrgcWRS8gqW04D4I+vJaZWY6k\nVpKSw2VaAZcCq8PxTlGbGBOZXu08SJxzDoj/rq07gZbAHcAvCaq3Jpa2gpnlSbodeBNIAuaY2RpJ\nt4TznwD6AnMlGbAGmBSu3hFYGD660hh4zswitxvfL2kQQRvKFoK7yapfdjZ06FAju3bOudqkzCAJ\nb+MdZ2Z3AweAm+PduJm9BrxWZNoTUZ8/AE6Psd5mYGAJ2/zXePefUNnZ0KtXTZfCOedqXJlVW2aW\nDwyvhrLULV615ZxzQPxVW59IWgT8CTgYmWhmf05IqWq7SBfyHiTOORd3kDQH9gDfippmQMMMktzc\nIEw8SJxzLu4n2+NuF2kQ/Kl255wrEO8bEp8huAIpxMz+rcpLVBd4kDjnXIF4q7ZejfrcnOD5je1V\nX5w6woPEOecKxFu19VL0uKTngfcSUqK6wIPEOecKxPtke1G9gJOrsiB1igeJc84ViLeNJJfCbSQ7\nCd5R0jB5kDjnXIF4q7aSE12QOiU7G5KS4KSyuhtzzrn6L973kYyR1CZqvK2kqxJXrFrOu5B3zrkC\n8baR3Gdm+yMjZrYPuC8xRaoDvHsU55wrEG+QxFou3luH6x8PEuecKxBvkKRLekjSN8LhIWBFIgtW\nq3mQOOdcgXiDZCpwFHgBmA8cAW5LVKFqPQ8S55wrEO9dWweBaQkuS93hQeKccwXivWvrLUlto8ZT\nJL0Zx3qjJG2QtElSsSAKt7NQ0ipJH0nqHzVvi6RPJWVISo+a3i4sz8bwZ/We0c28C3nnnIsSb9VW\nh/BOLQDMLJsynmwP36w4C7gM6AeMl9SvyGLTgQwzGwBMAB4pMv8iMxtkZmlR06YBi82sF7CY6r5S\nys2F/HwPEuecC8UbJMclnRoZkdSDGL0BFzEU2GRmm83sKEHbypVFlukHvANgZuuBHpI6lrHdK4G5\n4ee5QPU+z+JPtTvnXCHxBslPgfck/UHSH4G/AT8pY50uwNao8cxwWrSVwFgASUOB7kDXcJ4Bb0ta\nIWlK1DodzWxH+HknEDN4JE2RlC4pPSsrq4yiloMHiXPOFRJXkJjZG0AasAF4HvghcLgK9j8TaCsp\ng+DOsE+A/HDecDMbRFA1dpukC2KUyyjhysjMZptZmpmlpaamVkFRQx4kzjlXSLydNk4G7iS4WsgA\nzgE+oPCrd4vaBnSLGu8aTitgZjnAzeE+BHwBbA7nbQt/7pa0kKCqbBmwS1InM9shqROwO55jqDIe\nJM45V0i8VVt3AmcDX5rZRcBZwL7SV2E50EtST0lNgeuBRdELhH12NQ1HJwPLzCxHUitJyeEyrYBL\ngdXhcouAieHnicDLcR5D1fAgcc65QuLt5uSImR2RhKRmZrZeUu/SVjCzPEm3A28CScAcM1sj6ZZw\n/hNAX2CdwenPAAAXM0lEQVSuJAPWAJPC1TsCC4OLFBoDz4XVaxBUhy2QNAn4Ergu7qOtCh4kzjlX\nSLxBkhk+R/IX4C1J2QQn8VKZ2WvAa0WmPRH1+QPg9BjrbQYGlrDNPcDIOMtd9SJdyCd7z/rOOQfx\nP9k+Jvw4Q9ISoA3wRimr1F/Z2dC2rXch75xzoXL34Gtmf0tEQeoMf6rdOecKqeg72xsu72fLOecK\n8SApLw8S55wrxIOkvDxInHOuEA+S8vIgcc65QjxIysPMg8Q554rwICmPgwchL8+DxDnnoniQlIc/\n1e6cc8V4kJSHB4lzzhXjQVIeHiTOOVeMB0l5eJA451wxHiTl4UHinHPFeJCUhweJc84V40FSHtnZ\n0KiRdyHvnHNRPEjKIzsb2rQJwsQ55xyQ4CCRNErSBkmbJE2LMT9F0kJJqyR9JKl/kflJkj6R9GrU\ntBmStknKCIfLE3kMhfhT7c45V0zCgkRSEjALuAzoB4yX1K/IYtOBDDMbAEwAHiky/05gXYzN/8bM\nBoXDazHmJ4YHiXPOFZPIK5KhwCYz22xmR4H5wJVFlukHvANgZuuBHpI6AkjqClwBPJXAMpaPB4lz\nzhWTyCDpAmyNGs8Mp0VbCYwFkDQU6A50Dec9DNwDHI+x7alhddgcSTHP7JKmSEqXlJ6VlVWJw4ji\nQeKcc8XUdKvxTKCtpAxgKvAJkC/pO8BuM1sRY53HgdOAQcAO4MFYGzaz2WaWZmZpqampVVNaDxLn\nnCum3O9sL4dtQLeo8a7htAJmlgPcDCBJwBfAZmAcMDpsSG8OtJb0RzO70cx2RdaX9CTwKtXBu5B3\nzrmYEnlFshzoJamnpKbA9cCi6AUktQ3nAUwGlplZjpn9xMy6mlmPcL13zOzGcJ1OUZsYA6xO4DGc\ncOgQHDvmQeKcc0Uk7IrEzPIk3Q68CSQBc8xsjaRbwvlPAH2BuZIMWANMimPT90saBBiwBfhBIspf\njD/V7pxzMSWyaovw1tzXikx7IurzB8DpZWxjKbA0avxfq7SQ8fIgcc65mGq6sb3u8CBxzrmYPEji\n5UHinHMxeZDEy4PEOedi8iCJlweJc87F5EESr+xskILef51zzhXwIImXdyHvnHMx+VkxXv5Uu3PO\nxeRBEi8PEueci8mDJF4eJM45F5MHSbw8SJxzLiYPknh5kDjnXEweJPHwLuSdc65EHiTxOHwYjh71\nIHHOuRg8SOLhT7U751yJPEji4UHinHMlSmiQSBolaYOkTZKmxZifImmhpFWSPpLUv8j8JEmfSHo1\nalo7SW9J2hj+TPzZ3YPEOedKlLAgkZQEzAIuA/oB4yX1K7LYdCDDzAYAE4BHisy/E1hXZNo0YLGZ\n9QIWh+OJ5UHinHMlSuQVyVBgk5ltNrOjwHzgyiLL9APeATCz9UAPSR0BJHUFrgCeKrLOlcDc8PNc\n4KrEFD+KB4lzzpUokUHSBdgaNZ4ZTou2EhgLIGko0B3oGs57GLgHOF5knY5mtiP8vBPoWIVljs2D\nxDnnSlTTje0zgbaSMoCpwCdAvqTvALvNbEVpK5uZARZrnqQpktIlpWdlZVWulJEg8S7knXOumEQG\nyTagW9R413BaATPLMbObzWwQQRtJKrAZOA8YLWkLQZXYtyT9MVxtl6ROAOHP3bF2bmazzSzNzNJS\nU1MrdySRLuSTkiq3Heecq4cSGSTLgV6SekpqClwPLIpeQFLbcB7AZGBZGC4/MbOuZtYjXO8dM7sx\nXG4RMDH8PBF4OYHHEPCn2p1zrkSNE7VhM8uTdDvwJpAEzDGzNZJuCec/AfQF5koyYA0wKY5NzwQW\nSJoEfAlcl5ADiOZB4pxzJUpYkACY2WvAa0WmPRH1+QPg9DK2sRRYGjW+BxhZleUskweJq0eOHTtG\nZmYmR44cqemiuFqiefPmdO3alSZNmlRo/YQGSb2RnQ39ij4C41zdlJmZSXJyMj169EBSTRfH1TAz\nY8+ePWRmZtKzZ88KbaOm79qqG/yKxNUjR44coX379h4iDgBJtG/fvlJXqB4k8fAgcfWMh4iLVtl/\nDx4kZTl8GL7+2oPEOedK4EFSFn+q3bkad9JJJwGwfft2rrnmmpjLjBgxgvT09FK38/DDD3Po0KGC\n8csvv5x9+/ZVXUEbKA+SskT+kXmQOFfjOnfuzIsvvljh9YsGyWuvvUbbtm2romjVwsw4frxor1E1\nz4OkLH5F4uqxu+6CESOqdrjrrtL3OW3aNGbNmlUwPmPGDB544AEOHDjAyJEjGTx4MGeeeSYvv1z8\nWeMtW7bQv3/wtonDhw9z/fXX07dvX8aMGcPhw4cLlrv11ltJS0vjjDPO4L777gPg0UcfZfv27Vx0\n0UVcdNFFAPTo0YOvvvoKgIceeoj+/fvTv39/Hn744YL99e3bl+9///ucccYZXHrppYX2E/HKK68w\nbNgwzjrrLC6++GJ27doFwIEDB7j55ps588wzGTBgAC+99BIAb7zxBoMHD2bgwIGMHDmy0O8hon//\n/mzZsoUtW7bQu3dvJkyYQP/+/dm6dWvM4wNYvnw5//Iv/8LAgQMZOnQoubm5XHDBBWRkZBQsM3z4\ncFauXFn6l1ROfvtvWTxInKtS48aN46677uK2224DYMGCBbz55ps0b96chQsX0rp1a7766ivOOecc\nRo8eXWJD8OOPP07Lli1Zt24dq1atYvDgwQXzfvWrX9GuXTvy8/MZOXIkq1at4o477uChhx5iyZIl\ndOjQodC2VqxYwTPPPMM//vEPzIxhw4Zx4YUXkpKSwsaNG3n++ed58sknue6663jppZe48cYbC60/\nfPhwPvzwQyTx1FNPcf/99/Pggw/yy1/+kjZt2vDpp58CkJ2dTVZWFt///vdZtmwZPXv2ZO/evWX+\nzjZu3MjcuXM555xzSjy+Pn36MG7cOF544QXOPvtscnJyaNGiBZMmTeL3v/89Dz/8MJ999hlHjhxh\n4MCB8X9hcfAgKYsHiavHwj+8q9VZZ53F7t272b59O1lZWaSkpNCtWzeOHTvG9OnTWbZsGY0aNWLb\ntm3s2rWLU045JeZ2li1bxh133AHAgAEDGDBgQMG8BQsWMHv2bPLy8tixYwdr164tNL+o9957jzFj\nxtCqVSsAxo4dy7vvvsvo0aPp2bMngwYNAmDIkCFs2bKl2PqZmZmMGzeOHTt2cPTo0YLnMd5++23m\nz59fsFxKSgqvvPIKF1xwQcEy7dq1K/N31r1794IQKen4JNGpUyfOPvtsAFq3bg3Atddeyy9/+Ut+\n/etfM2fOHG666aYy91deHiRl8SBxrspde+21vPjii+zcuZNx48YBMG/ePLKyslixYgVNmjShR48e\nFXq24YsvvuCBBx5g+fLlpKSkcNNNN1XqGYlmzZoVfE5KSopZtTV16lT+4z/+g9GjR7N06VJmzJhR\n7v00bty4UPtHdJkjAQflP76WLVtyySWX8PLLL7NgwQJWrCi1U/UK8TaSskSCpA41yDlX240bN475\n8+fz4osvcu211wKwf/9+Tj75ZJo0acKSJUv48ssvS93GBRdcwHPPPQfA6tWrWbVqFQA5OTm0atWK\nNm3asGvXLl5//fWCdZKTk8nNzS22rfPPP5+//OUvHDp0iIMHD7Jw4ULOP//8uI9n//79dOkSvG5p\n7ty5BdMvueSSQu1B2dnZnHPOOSxbtowvvvgCoKBqq0ePHnz88ccAfPzxxwXziyrp+Hr37s2OHTtY\nvnw5ALm5ueTl5QEwefJk7rjjDs4++2xSEvBHsQdJWbKzoXVr70LeuSp0xhlnkJubS5cuXejUqRMA\n3/ve90hPT+fMM8/k2WefpU+fPqVu49Zbb+XAgQP07duXe++9lyFDhgAwcOBAzjrrLPr06cMNN9zA\neeedV7DOlClTGDVqVEFje8TgwYO56aabGDp0KMOGDWPy5MmcddZZcR/PjBkzuPbaaxkyZEih9pef\n/exnZGdn079/fwYOHMiSJUtITU1l9uzZjB07loEDBxZckV199dXs3buXM844g8cee4zTT4/dDWFJ\nx9e0aVNeeOEFpk6dysCBA7nkkksKrlSGDBlC69atufnmm+M+pvJQ8G6o+i0tLc3Kur+8RBMnwt/+\nBjHqRZ2ri9atW0ffvn1ruhiuGm3fvp0RI0awfv16GjWKff0Q69+FpBVmllbW9v2KpCzePYpzrg57\n9tlnGTZsGL/61a9KDJHK8sb2sniQOOfqsAkTJjBhwoSE7sOvSMriQeKcc6VKaJBIGiVpg6RNkqbF\nmJ8iaaGkVZI+ktQ/nN48HF8paY2kX0StM0PSNkkZ4XB5Io/Bg8Q550qXsCCRlATMAi4D+gHjJRV9\nO9R0IMPMBgATgEfC6V8D3zKzgcAgYJSkc6LW+42ZDQqH10gkDxLnnCtVIq9IhgKbzGyzmR0F5gNX\nFlmmH/AOgJmtB3pI6miBA+EyTcKh+m8v+/rroBt5DxLnnCtRIoOkC7A1ajwznBZtJTAWQNJQoDvQ\nNRxPkpQB7AbeMrN/RK03NawOmyMp5lle0hRJ6ZLSs7KyKnYE/lS7c1Vu3759/O53v6vQut7te+1U\n043tM4G2YWBMBT4B8gHMLN/MBhEEy9BI+wnwOHAaQZXXDuDBWBs2s9lmlmZmaampqRUrnT/V7lyV\nKy1IIk9il6S2dvteW7t3ry6JvP13G9AtarxrOK2AmeUANwMo6OLzC2BzkWX2SVoCjAJWm9muyDxJ\nTwKvJqT04Fckrv676y6I6mK8SgwaVGpvkNOmTePzzz9n0KBBXHLJJVxxxRX8/Oc/JyUlhfXr1/PZ\nZ59x1VVXsXXrVo4cOcKdd97JlClTgKAbkfT0dA4cOMBll13G8OHDef/99+nSpQsvv/wyLVq0KLSv\nV155hf/6r//i6NGjtG/fnnnz5tGxY0cOHDjA1KlTSU9PRxL33XcfV199NW+88QbTp08nPz+fDh06\nsHjxYmbMmMFJJ53E3XffDQTdu7/6anDa+fa3v82wYcNYsWIFr732GjNnzmT58uUcPnyYa665hl/8\nIrhPaPny5dx5550cPHiQZs2asXjxYq644goeffTRgg4hhw8fzqxZs6q8Z97qkMggWQ70ktSTIECu\nB26IXkBSW+BQ2IYyGVhmZjmSUoFjYYi0AC4B/idcp5OZ7Qg3MQZYnbAj8CBxrsrNnDmT1atXF7wj\nY+nSpXz88cesXr26oEfcOXPm0K5dOw4fPszZZ5/N1VdfTfv27Qttx7t3rz0SFiRmlifpduBNIAmY\nY2ZrJN0Szn8C6AvMlWTAGmBSuHqncHoSQfXbAjOLXHncL2kQQeP7FuAHiToGDxJX79VEP/IxDB06\ntCBEIHgJ1cKFCwHYunUrGzduLBYk3r177ZHQJ9vDW3NfKzLtiajPHwDFeiYzs1VAzB7TzOxfq7iY\nJfMgca5aRHeTvnTpUt5++20++OADWrZsyYgRI2J2k+7du9ceNd3YXrt5Y7tzVa6krtwj9u/fT0pK\nCi1btmT9+vV8+OGHFd5XQ+/evbp4kJQmOxtOOgmaNKnpkjhXb7Rv357zzjuP/v3786Mf/ajY/FGj\nRpGXl0ffvn2ZNm1aoaqj8mro3btXF+9GvjRPPw3vvx/8dK6e8G7ka494unevLt6NfKJMmuQh4pxL\niOro3r26eDfyzjlXA6qje/fqUrdj0DlXIQ2hStvFr7L/HjxInGtgmjdvzp49ezxMHBCEyJ49e2je\nvHmFt+FVW841MF27diUzM5MKd2bq6p3mzZvTtWvXCq/vQeJcA9OkSZNCT5E7V1leteWcc65SPEic\nc85VigeJc865SmkQT7ZLygK+rODqHYCvqrA4NcGPoXaoD8cA9eM4/Bji093MynwzYIMIksqQlB5P\nFwG1mR9D7VAfjgHqx3H4MVQtr9pyzjlXKR4kzjnnKsWDpGyza7oAVcCPoXaoD8cA9eM4/BiqkLeR\nOOecqxS/InHOOVcpHiTOOecqxYOkFJJGSdogaZOkaTVdnoqQtEXSp5IyJFXgNZHVT9IcSbslrY6a\n1k7SW5I2hj9r9QuuSziGGZK2hd9FhqTLa7KMZZHUTdISSWslrZF0Zzi9znwXpRxDnfkuJDWX9JGk\nleEx/CKcXmu+B28jKYGkJOAz4BIgE1gOjDeztTVasHKStAVIM7M68/CVpAuAA8CzZtY/nHY/sNfM\nZoahnmJmP67JcpamhGOYARwwswdqsmzxktQJ6GRmH0tKBlYAVwE3UUe+i1KO4TrqyHchSUArMzsg\nqQnwHnAnMJZa8j34FUnJhgKbzGyzmR0F5gNX1nCZGgQzWwbsLTL5SmBu+Hkuwcmg1irhGOoUM9th\nZh+Hn3OBdUAX6tB3Ucox1BkWOBCONgkHoxZ9Dx4kJesCbI0az6SO/QMMGfC2pBWSptR0YSqho5nt\nCD/vBDrWZGEqYaqkVWHVV62tEipKUg/gLOAf1NHvosgxQB36LiQlScoAdgNvmVmt+h48SOq/4WY2\nCLgMuC2scqnTLKiPrYt1so8DpwGDgB3AgzVbnPhIOgl4CbjLzHKi59WV7yLGMdSp78LM8sP/x12B\noZL6F5lfo9+DB0nJtgHdosa7htPqFDPbFv7cDSwkqLKri3aF9d2Reu/dNVyecjOzXeEJ4TjwJHXg\nuwjr5F8C5pnZn8PJdeq7iHUMdfG7ADCzfcASYBS16HvwICnZcqCXpJ6SmgLXA4tquEzlIqlV2MCI\npFbApcDq0teqtRYBE8PPE4GXa7AsFRL5Tx8aQy3/LsJG3qeBdWb2UNSsOvNdlHQMdem7kJQqqW34\nuQXBDUDrqUXfg9+1VYrwlsCHgSRgjpn9qoaLVC6STiO4CoHgtcrP1YVjkPQ8MIKgm+xdwH3AX4AF\nwKkErwS4zsxqbWN2CccwgqAqxYAtwA+i6rhrHUnDgXeBT4Hj4eTpBG0MdeK7KOUYxlNHvgtJAwga\n05MI/vhfYGb/Kak9teR78CBxzjlXKV615ZxzrlI8SJxzzlWKB4lzzrlK8SBxzjlXKR4kzjnnKsWD\nxDU4kt4Pf/aQdEMVb3t6rH1VwXZvktQ5avwpSf2qYtvOVZbf/usaLEkjgLvN7DvlWKexmeWVMv+A\nmZ1UFeUrst2lBGWtE68CcA2LX5G4BkdSpCfVmcD54fso/j3sGO/XkpaHnfn9IFx+hKR3JS0C1obT\n/hJ2hLkm0hmmpJlAi3B786L3pcCvJa1W8H6YcVHbXirpRUnrJc0Ln8aOLu81QBowL9x2i3CdtMg+\nwm2vkfS2pKHh/M2SRofLlHRsnSQtC7e7WtL5ifzdu3rKzHzwoUENBO+hgOBJ81ejpk8BfhZ+bgak\nAz3D5Q4CPaOWbRf+bEHQvUb76G3H2NfVwFsETyd3BP4JdAq3vZ+gL7dGwAcEHW0WLfNSgvfKFBsn\neDr7svDzQuCvBF2NDwQyyji2HwI/DacnAck1/f34UPeGxpUJIefqmUuBAeEVAEAboBdwFPjIzL6I\nWvYOSWPCz93C5faUsu3hwPNmlk/Q2d7fgLOBnHDbmQBhV+E9CF5eFK+jwBvh50+Br83smKRPw22V\ndmzLgTlhx4Z/MbOMcuzXOQAPEueiCJhqZm8Wmhi0pRwsMn4xcK6ZHQrbL5pXYr9fR33Op/z/L4+Z\nWaSx83hke2Z2XFJkWzGPDQre5ngF8HtJD5nZs+Xcv2vgvI3ENWS5QHLU+JvAreFf50g6Pew1uag2\nQHYYIn2Ac6LmHYusX8S7wLiwrSIVuAD4qBJlLa+YxyapO7DLzJ4EngIGV2IfroHyKxLXkK0C8iWt\nBH4PPEJQFfRx2OCdRezXl74B3CJpHbAB+DBq3mxglaSPzex7UdMXAucCKwnaNO4xs51hEMXj98AT\nkg6H2ymvp4h9bCOAH0k6RvCO+QkV2LZr4Pz2X+ecc5XiVVvOOecqxYPEOedcpXiQOOecqxQPEuec\nc5XiQeKcc65SPEicc85VigeJc865Svn/plMx4/zHYlMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19358647f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Accuracy')\n",
    "steps = [i for i in range(32)]\n",
    "plt.plot(steps, val_accs, color='blue', label='validation accuracy')\n",
    "plt.plot(steps, training_accs, color='red', label='train accuracy')\n",
    "plt.legend() # æ˜¾ç¤ºå›¾ä¾‹\n",
    "\n",
    "plt.xlabel('iteration times')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
