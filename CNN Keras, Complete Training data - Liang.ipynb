{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LDH\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras \n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path to saved model weights(as hdf5)\n",
    "resume_weights = \"model/net-cnn-best.hdf5\"\n",
    "\n",
    "# Hyper-parameters\n",
    "batch_size = 128\n",
    "num_classes = 15\n",
    "epochs = 32\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 64, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PATH = 'tmp/x_train/balanced-raw0_10000'\n",
    "temp = pd.read_csv(PATH, dtype=np.uint8, sep=',', header=None, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>2048</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1     2     3     4     5     6     7     8     9     10    ...   2039  \\\n",
       "0                                                              ...          \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "\n",
       "   2040  2041  2042  2043  2044  2045  2046  2047  2048  \n",
       "0                                                        \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 2048 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>2048</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1     2     3     4     5     6     7     8     9     10    ...   2039  \\\n",
       "0                                                              ...          \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     1     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "\n",
       "   2040  2041  2042  2043  2044  2045  2046  2047  2048  \n",
       "0                                                        \n",
       "0     0     0     1     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 2048 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2048)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_name_sorted(path):\n",
    "    fileNames = os.listdir(path)\n",
    "    li = list()\n",
    "    for name in fileNames:\n",
    "        index = int(name.rsplit('_', 1)[1])\n",
    "        li.append((index, name))\n",
    "\n",
    "    li = sorted(li, key=lambda x: x[0])\n",
    "    return [i for (_, i) in li]\n",
    "\n",
    "def get_training_data():\n",
    "    y_train_path = 'tmp/y_train/y_train_raw'\n",
    "    x_train_path = 'tmp/x_train'\n",
    "    \n",
    "    y_train0 = pd.read_csv(y_train_path, dtype=np.uint8, sep=',', header=None, index_col=0)\n",
    "    \n",
    "    x_train_files = get_file_name_sorted(x_train_path)\n",
    "    x_train0 = None\n",
    "    for i in range(len(x_train_files)):\n",
    "#     for i in range(1):\n",
    "        file_path = x_train_path+'/'+x_train_files[i]\n",
    "        print(file_path)\n",
    "        if i == 0:\n",
    "            x_train0 = pd.read_csv(file_path, dtype=np.uint8, sep=',', header=None, index_col=0)\n",
    "            print(x_train0.shape)\n",
    "        else:\n",
    "            temp = pd.read_csv(file_path, dtype=np.uint8, sep=',', header=None, index_col=0)\n",
    "            x_train0 = pd.concat([pd.DataFrame(x_train0), pd.DataFrame(temp)])\n",
    "        \n",
    "    return (x_train0, y_train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LDH\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/x_train/balanced-raw0_10000\n",
      "(10000, 2048)\n",
      "tmp/x_train/balanced-raw10000_20000\n",
      "tmp/x_train/balanced-raw20000_30000\n",
      "tmp/x_train/balanced-raw30000_40000\n",
      "tmp/x_train/balanced-raw40000_50000\n",
      "tmp/x_train/balanced-raw50000_60000\n",
      "tmp/x_train/balanced-raw60000_70000\n",
      "tmp/x_train/balanced-raw70000_80000\n",
      "tmp/x_train/balanced-raw80000_90000\n",
      "tmp/x_train/balanced-raw90000_100000\n",
      "tmp/x_train/balanced-raw100000_110000\n",
      "tmp/x_train/balanced-raw110000_120000\n",
      "tmp/x_train/balanced-raw120000_130000\n",
      "tmp/x_train/balanced-raw130000_140000\n",
      "tmp/x_train/balanced-raw140000_150000\n",
      "tmp/x_train/balanced-raw150000_160000\n",
      "tmp/x_train/balanced-raw160000_170000\n",
      "tmp/x_train/balanced-raw170000_180000\n",
      "tmp/x_train/balanced-raw180000_190000\n",
      "tmp/x_train/balanced-raw190000_200000\n",
      "tmp/x_train/balanced-raw200000_210000\n",
      "tmp/x_train/balanced-raw210000_220000\n",
      "tmp/x_train/balanced-raw220000_230000\n",
      "tmp/x_train/balanced-raw230000_240000\n",
      "tmp/x_train/balanced-raw240000_250000\n",
      "tmp/x_train/balanced-raw250000_260000\n",
      "tmp/x_train/balanced-raw260000_270000\n",
      "tmp/x_train/balanced-raw270000_280000\n",
      "tmp/x_train/balanced-raw280000_290000\n",
      "tmp/x_train/balanced-raw290000_300000\n",
      "tmp/x_train/balanced-raw300000_310000\n",
      "tmp/x_train/balanced-raw310000_320000\n",
      "tmp/x_train/balanced-raw320000_330000\n",
      "tmp/x_train/balanced-raw330000_340000\n",
      "tmp/x_train/balanced-raw340000_350000\n",
      "tmp/x_train/balanced-raw350000_360000\n",
      "tmp/x_train/balanced-raw360000_370000\n",
      "tmp/x_train/balanced-raw370000_380000\n",
      "tmp/x_train/balanced-raw380000_390000\n",
      "tmp/x_train/balanced-raw390000_400000\n",
      "tmp/x_train/balanced-raw400000_410000\n",
      "tmp/x_train/balanced-raw410000_420000\n",
      "tmp/x_train/balanced-raw420000_430000\n",
      "tmp/x_train/balanced-raw430000_440000\n",
      "tmp/x_train/balanced-raw440000_450000\n",
      "tmp/x_train/balanced-raw450000_460000\n",
      "tmp/x_train/balanced-raw460000_470000\n",
      "tmp/x_train/balanced-raw470000_480000\n",
      "tmp/x_train/balanced-raw480000_490000\n",
      "tmp/x_train/balanced-raw490000_500000\n",
      "tmp/x_train/balanced-raw500000_510000\n",
      "tmp/x_train/balanced-raw510000_520000\n",
      "tmp/x_train/balanced-raw520000_530000\n",
      "tmp/x_train/balanced-raw530000_540000\n",
      "tmp/x_train/balanced-raw540000_550000\n",
      "tmp/x_train/balanced-raw550000_560000\n",
      "tmp/x_train/balanced-raw560000_570000\n",
      "tmp/x_train/balanced-raw570000_580000\n",
      "tmp/x_train/balanced-raw580000_590000\n",
      "tmp/x_train/balanced-raw590000_600000\n",
      "tmp/x_train/balanced-raw600000_610000\n",
      "tmp/x_train/balanced-raw610000_620000\n",
      "tmp/x_train/balanced-raw620000_630000\n",
      "tmp/x_train/balanced-raw630000_640000\n",
      "tmp/x_train/balanced-raw640000_650000\n",
      "tmp/x_train/balanced-raw650000_660000\n",
      "tmp/x_train/balanced-raw660000_670000\n",
      "tmp/x_train/balanced-raw670000_680000\n",
      "tmp/x_train/balanced-raw680000_690000\n",
      "tmp/x_train/balanced-raw690000_700000\n",
      "tmp/x_train/balanced-raw700000_710000\n",
      "tmp/x_train/balanced-raw710000_720000\n",
      "tmp/x_train/balanced-raw720000_730000\n",
      "tmp/x_train/balanced-raw730000_740000\n",
      "tmp/x_train/balanced-raw740000_750000\n",
      "tmp/x_train/balanced-raw750000_760000\n",
      "tmp/x_train/balanced-raw760000_770000\n",
      "tmp/x_train/balanced-raw770000_780000\n",
      "tmp/x_train/balanced-raw780000_790000\n",
      "tmp/x_train/balanced-raw790000_800000\n",
      "tmp/x_train/balanced-raw800000_810000\n",
      "tmp/x_train/balanced-raw810000_820000\n",
      "tmp/x_train/balanced-raw820000_830000\n",
      "tmp/x_train/balanced-raw830000_840000\n",
      "tmp/x_train/balanced-raw840000_850000\n",
      "tmp/x_train/balanced-raw850000_860000\n",
      "tmp/x_train/balanced-raw860000_870000\n",
      "tmp/x_train/balanced-raw870000_880000\n",
      "tmp/x_train/balanced-raw880000_890000\n",
      "tmp/x_train/balanced-raw890000_900000\n",
      "tmp/x_train/balanced-raw900000_910000\n",
      "tmp/x_train/balanced-raw910000_920000\n",
      "tmp/x_train/balanced-raw920000_930000\n",
      "tmp/x_train/balanced-raw930000_940000\n",
      "tmp/x_train/balanced-raw940000_950000\n",
      "tmp/x_train/balanced-raw950000_960000\n",
      "tmp/x_train/balanced-raw960000_970000\n",
      "tmp/x_train/balanced-raw970000_980000\n",
      "tmp/x_train/balanced-raw980000_990000\n",
      "tmp/x_train/balanced-raw990000_1000000\n",
      "tmp/x_train/balanced-raw1000000_1010000\n",
      "tmp/x_train/balanced-raw1010000_1020000\n",
      "tmp/x_train/balanced-raw1020000_1030000\n",
      "tmp/x_train/balanced-raw1030000_1040000\n",
      "tmp/x_train/balanced-raw1040000_1050000\n",
      "tmp/x_train/balanced-raw1050000_1060000\n",
      "tmp/x_train/balanced-raw1060000_1070000\n",
      "tmp/x_train/balanced-raw1070000_1080000\n",
      "tmp/x_train/balanced-raw1080000_1090000\n",
      "tmp/x_train/balanced-raw1090000_1100000\n",
      "tmp/x_train/balanced-raw1100000_1110000\n",
      "tmp/x_train/balanced-raw1110000_1120000\n",
      "tmp/x_train/balanced-raw1120000_1130000\n",
      "tmp/x_train/balanced-raw1130000_1140000\n",
      "tmp/x_train/balanced-raw1140000_1150000\n",
      "tmp/x_train/balanced-raw1150000_1160000\n",
      "tmp/x_train/balanced-raw1160000_1170000\n",
      "tmp/x_train/balanced-raw1170000_1180000\n",
      "tmp/x_train/balanced-raw1180000_1190000\n",
      "tmp/x_train/balanced-raw1190000_1200000\n",
      "tmp/x_train/balanced-raw1200000_1210000\n",
      "tmp/x_train/balanced-raw1210000_1220000\n",
      "tmp/x_train/balanced-raw1220000_1230000\n",
      "tmp/x_train/balanced-raw1230000_1240000\n",
      "tmp/x_train/balanced-raw1240000_1250000\n",
      "tmp/x_train/balanced-raw1250000_1260000\n",
      "tmp/x_train/balanced-raw1260000_1270000\n",
      "tmp/x_train/balanced-raw1270000_1280000\n",
      "tmp/x_train/balanced-raw1280000_1290000\n",
      "tmp/x_train/balanced-raw1290000_1300000\n",
      "tmp/x_train/balanced-raw1300000_1310000\n",
      "tmp/x_train/balanced-raw1310000_1320000\n",
      "tmp/x_train/balanced-raw1320000_1330000\n",
      "tmp/x_train/balanced-raw1330000_1340000\n",
      "tmp/x_train/balanced-raw1340000_1350000\n",
      "tmp/x_train/balanced-raw1350000_1360000\n",
      "tmp/x_train/balanced-raw1360000_1370000\n",
      "tmp/x_train/balanced-raw1370000_1380000\n",
      "tmp/x_train/balanced-raw1380000_1390000\n",
      "tmp/x_train/balanced-raw1390000_1400000\n",
      "tmp/x_train/balanced-raw1400000_1410000\n",
      "tmp/x_train/balanced-raw1410000_1420000\n",
      "tmp/x_train/balanced-raw1420000_1430000\n",
      "tmp/x_train/balanced-raw1430000_1440000\n",
      "tmp/x_train/balanced-raw1440000_1450000\n",
      "tmp/x_train/balanced-raw1450000_1460000\n",
      "tmp/x_train/balanced-raw1460000_1470000\n",
      "tmp/x_train/balanced-raw1470000_1480000\n",
      "tmp/x_train/balanced-raw1480000_1490000\n",
      "tmp/x_train/balanced-raw1490000_1500000\n",
      "tmp/x_train/balanced-raw1500000_1510000\n",
      "tmp/x_train/balanced-raw1510000_1520000\n",
      "tmp/x_train/balanced-raw1520000_1530000\n",
      "tmp/x_train/balanced-raw1530000_1540000\n",
      "tmp/x_train/balanced-raw1540000_1550000\n",
      "tmp/x_train/balanced-raw1550000_1560000\n",
      "tmp/x_train/balanced-raw1560000_1570000\n",
      "tmp/x_train/balanced-raw1570000_1580000\n",
      "tmp/x_train/balanced-raw1580000_1590000\n",
      "tmp/x_train/balanced-raw1590000_1600000\n",
      "tmp/x_train/balanced-raw1600000_1610000\n",
      "tmp/x_train/balanced-raw1610000_1620000\n",
      "tmp/x_train/balanced-raw1620000_1630000\n",
      "tmp/x_train/balanced-raw1630000_1640000\n",
      "tmp/x_train/balanced-raw1640000_1650000\n",
      "tmp/x_train/balanced-raw1650000_1660000\n",
      "tmp/x_train/balanced-raw1660000_1670000\n",
      "tmp/x_train/balanced-raw1670000_1680000\n",
      "tmp/x_train/balanced-raw1680000_1690000\n",
      "tmp/x_train/balanced-raw1690000_1700000\n",
      "tmp/x_train/balanced-raw1700000_1710000\n",
      "tmp/x_train/balanced-raw1710000_1720000\n",
      "tmp/x_train/balanced-raw1720000_1730000\n",
      "tmp/x_train/balanced-raw1730000_1740000\n",
      "tmp/x_train/balanced-raw1740000_1750000\n",
      "tmp/x_train/balanced-raw1750000_1760000\n",
      "tmp/x_train/balanced-raw1760000_1770000\n",
      "tmp/x_train/balanced-raw1770000_1780000\n",
      "tmp/x_train/balanced-raw1780000_1790000\n",
      "tmp/x_train/balanced-raw1790000_1800000\n",
      "tmp/x_train/balanced-raw1800000_1810000\n",
      "tmp/x_train/balanced-raw1810000_1820000\n",
      "tmp/x_train/balanced-raw1820000_1830000\n",
      "tmp/x_train/balanced-raw1830000_1840000\n",
      "tmp/x_train/balanced-raw1840000_1850000\n",
      "tmp/x_train/balanced-raw1850000_1860000\n",
      "tmp/x_train/balanced-raw1860000_1870000\n",
      "tmp/x_train/balanced-raw1870000_1880000\n",
      "tmp/x_train/balanced-raw1880000_1890000\n",
      "tmp/x_train/balanced-raw1890000_1900000\n",
      "tmp/x_train/balanced-raw1900000_1910000\n",
      "tmp/x_train/balanced-raw1910000_1920000\n",
      "tmp/x_train/balanced-raw1920000_1930000\n",
      "tmp/x_train/balanced-raw1930000_1940000\n",
      "tmp/x_train/balanced-raw1940000_1950000\n",
      "tmp/x_train/balanced-raw1950000_1960000\n",
      "tmp/x_train/balanced-raw1960000_1970000\n",
      "tmp/x_train/balanced-raw1970000_1980000\n",
      "tmp/x_train/balanced-raw1980000_1990000\n",
      "tmp/x_train/balanced-raw1990000_2000000\n",
      "tmp/x_train/balanced-raw2000000_2010000\n",
      "tmp/x_train/balanced-raw2010000_2020000\n",
      "tmp/x_train/balanced-raw2020000_2030000\n",
      "tmp/x_train/balanced-raw2030000_2038140\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train = get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2038140, 2048) (2038140, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>2048</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1     2     3     4     5     6     7     8     9     10    ...   2039  \\\n",
       "0                                                              ...          \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "\n",
       "   2040  2041  2042  2043  2044  2045  2046  2047  2048  \n",
       "0                                                        \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 2048 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>2048</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1     2     3     4     5     6     7     8     9     10    ...   2039  \\\n",
       "0                                                              ...          \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     1     0     0     0     0     0     0     0  ...      0   \n",
       "0     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "\n",
       "   2040  2041  2042  2043  2044  2045  2046  2047  2048  \n",
       "0                                                        \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 2048 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_val_data():\n",
    "    x_val_path = \"tmp/X_val/X_val_raw\"\n",
    "    y_val_path = \"tmp/y_val/y_val_raw\"\n",
    "    \n",
    "    x_val = pd.read_csv(x_val_path, dtype=np.uint8, sep=',', header=None, index_col=0)\n",
    "    y_val = pd.read_csv(y_val_path, dtype=np.uint8, sep=',', header=None, index_col=0)\n",
    "    return (x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val, y_val = get_val_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226460, 2048) (226460, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test, y_test = x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    x_test_path = 'tmp/X_test/X_test_raw'\n",
    "    y_test_path = \"tmp/y_test/y_test_raw\"\n",
    "   \n",
    "    x_test = pd.read_csv(x_test_path, dtype=np.uint8, sep=',', header=None, index_col=0)\n",
    "    y_test = pd.read_csv(y_test_path, dtype=np.uint8, sep=',', header=None, index_col=0)\n",
    "    \n",
    "    return (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (2038140, 64, 32, 1)\n",
      "2038140 train samples\n",
      "226460 test samples\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "(2038140, 15) (226460, 15)\n"
     ]
    }
   ],
   "source": [
    "# MNIST handwritten image classification\n",
    "# the data, shuffled and split between train and test sets\n",
    "\n",
    "# Reshape strategy according to backend\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.values.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.values.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    # 1 x 28 x 28 [number_of_channels (colors) x height x weight]\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.values.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.values.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    # 28 x 28 x 1 [height x weight x number_of_channels (colors)]\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "# Reshape, type, normalized, print\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_test = x_test.astype('float32')\n",
    "# x_train /= 255\n",
    "# x_test /= 255\n",
    "\n",
    "# Dataset info\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(np.unique(y_train), np.unique(y_test))\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2038140, 15)\n",
      "(226460, 15)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildModel():\n",
    "    # MODEL\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', \n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, (3, 2), activation='relu'))\n",
    "   \n",
    "    model.add(Conv2D(256, (3, 2), activation='relu'))\n",
    "  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "   \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation=Activation(tf.nn.softmax)))\n",
    "    # CEE, Adam\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "            optimizer=keras.optimizers.Adam(),\n",
    "            metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(model, is_resume_weight = False, resume_weights_path=''):\n",
    "    # If exists a best model, load its weights!\n",
    "    if is_resume_weight:\n",
    "        if os.path.isfile(resume_weights_path):\n",
    "            print (\"Resumed model's weights from {}\".format(resume_weights))\n",
    "            # load weights\n",
    "            model.load_weights(resume_weights_path)\n",
    "            return \n",
    "\n",
    "\n",
    "    # Checkpoint In the /output folder\n",
    "    filepath = \"output/net-cnn-best_callback.hdf5\"\n",
    "    os.makedirs('output', exist_ok=True)\n",
    "\n",
    "    # Keep only a single checkpoint, the best over test accuracy.\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"logs\\{}\".format(str(datetime.datetime.now().strftime('%Y%m%d_%H_%M_%S'))), histogram_freq=1)\n",
    "\n",
    "    # Train\n",
    "    hist = model.fit(x_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_data=(x_test, y_test), \n",
    "                callbacks=[tensorboard_callback, checkpoint])\n",
    "    print(hist.history.keys())\n",
    "    \n",
    "    print(hist.history['acc'])\n",
    "    print(hist.history['loss'])\n",
    "    print(hist.history['val_loss'])\n",
    "    print(hist.history['val_acc'])\n",
    "    model.save_weights(\"output/net-cnn-best_final.hdf5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 13, 128)       49280     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 26, 12, 256)       196864    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 6, 256)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 19968)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               5112064   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                3855      \n",
      "=================================================================\n",
      "Total params: 5,380,879\n",
      "Trainable params: 5,380,879\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LDH\\Anaconda3\\lib\\site-packages\\keras\\activations.py:197: UserWarning: Do not pass a layer instance (such as Activation) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session() # It is important if to create the model twice\n",
    "tf.summary.FileWriterCache.clear()\n",
    "\n",
    "model = buildModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11492347648393635105\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9290641572\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 9885025509701740664\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0\"\n",
      "]\n",
      "2.2.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/gpu:0']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(keras.__version__)\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2038140 samples, validate on 226460 samples\n",
      "Epoch 1/32\n",
      "2038140/2038140 [==============================] - 597s 293us/step - loss: 0.1997 - acc: 0.8979 - val_loss: 0.2150 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93685, saving model to output/net-cnn-best_callback.hdf5\n",
      "Epoch 2/32\n",
      "2038140/2038140 [==============================] - 594s 292us/step - loss: 0.1789 - acc: 0.9044 - val_loss: 0.2038 - val_acc: 0.9374\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.93685 to 0.93736, saving model to output/net-cnn-best_callback.hdf5\n",
      "Epoch 3/32\n",
      "2038140/2038140 [==============================] - 594s 291us/step - loss: 0.1770 - acc: 0.9051 - val_loss: 0.2100 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.93736 to 0.93867, saving model to output/net-cnn-best_callback.hdf5\n",
      "Epoch 4/32\n",
      "2038140/2038140 [==============================] - 594s 291us/step - loss: 0.1762 - acc: 0.9054 - val_loss: 0.1987 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.93867\n",
      "Epoch 5/32\n",
      "2038140/2038140 [==============================] - 595s 292us/step - loss: 0.1759 - acc: 0.9055 - val_loss: 0.1976 - val_acc: 0.9386\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.93867\n",
      "Epoch 6/32\n",
      "2038140/2038140 [==============================] - 595s 292us/step - loss: 0.1756 - acc: 0.9058 - val_loss: 0.1975 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.93867\n",
      "Epoch 7/32\n",
      "2038140/2038140 [==============================] - 594s 292us/step - loss: 0.1755 - acc: 0.9058 - val_loss: 0.1983 - val_acc: 0.9374\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.93867\n",
      "Epoch 8/32\n",
      "2038140/2038140 [==============================] - 593s 291us/step - loss: 0.1755 - acc: 0.9059 - val_loss: 0.1990 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.93867\n",
      "Epoch 9/32\n",
      "2038140/2038140 [==============================] - 594s 291us/step - loss: 0.1753 - acc: 0.9059 - val_loss: 0.2013 - val_acc: 0.9370\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.93867\n",
      "Epoch 10/32\n",
      "2038140/2038140 [==============================] - 593s 291us/step - loss: 0.1753 - acc: 0.9061 - val_loss: 0.1976 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.93867\n",
      "Epoch 11/32\n",
      "2038140/2038140 [==============================] - 594s 291us/step - loss: 0.1752 - acc: 0.9060 - val_loss: 0.2052 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.93867\n",
      "Epoch 12/32\n",
      "2038140/2038140 [==============================] - 593s 291us/step - loss: 0.1752 - acc: 0.9060 - val_loss: 0.1964 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.93867\n",
      "Epoch 13/32\n",
      "2038140/2038140 [==============================] - 594s 291us/step - loss: 0.1754 - acc: 0.9062 - val_loss: 0.1980 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.93867\n",
      "Epoch 14/32\n",
      "2038140/2038140 [==============================] - 594s 291us/step - loss: 0.1753 - acc: 0.9060 - val_loss: 0.2026 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.93867\n",
      "Epoch 15/32\n",
      "2038140/2038140 [==============================] - 611s 300us/step - loss: 0.1753 - acc: 0.9062 - val_loss: 0.2004 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.93867\n",
      "Epoch 16/32\n",
      "2038140/2038140 [==============================] - 607s 298us/step - loss: 0.1752 - acc: 0.9062 - val_loss: 0.2086 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.93867\n",
      "Epoch 17/32\n",
      "2038140/2038140 [==============================] - 609s 299us/step - loss: 0.1755 - acc: 0.9063 - val_loss: 0.1946 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.93867\n",
      "Epoch 18/32\n",
      "2038140/2038140 [==============================] - 610s 299us/step - loss: 0.1754 - acc: 0.9062 - val_loss: 0.2031 - val_acc: 0.9374\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.93867\n",
      "Epoch 19/32\n",
      "2038140/2038140 [==============================] - 611s 300us/step - loss: 0.1754 - acc: 0.9062 - val_loss: 0.2036 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.93867\n",
      "Epoch 20/32\n",
      "2038140/2038140 [==============================] - 593s 291us/step - loss: 0.1755 - acc: 0.9061 - val_loss: 0.2002 - val_acc: 0.9374\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.93867\n",
      "Epoch 21/32\n",
      "2038140/2038140 [==============================] - 611s 300us/step - loss: 0.1758 - acc: 0.9060 - val_loss: 0.1985 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.93867\n",
      "Epoch 22/32\n",
      "2038140/2038140 [==============================] - 594s 292us/step - loss: 0.1756 - acc: 0.9062 - val_loss: 0.2191 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.93867\n",
      "Epoch 23/32\n",
      "2038140/2038140 [==============================] - 604s 296us/step - loss: 0.1756 - acc: 0.9062 - val_loss: 0.2008 - val_acc: 0.9388\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.93867 to 0.93879, saving model to output/net-cnn-best_callback.hdf5\n",
      "Epoch 24/32\n",
      "2038140/2038140 [==============================] - 611s 300us/step - loss: 0.1759 - acc: 0.9061 - val_loss: 0.2021 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.93879\n",
      "Epoch 25/32\n",
      "2038140/2038140 [==============================] - 612s 300us/step - loss: 0.1759 - acc: 0.9060 - val_loss: 0.1938 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.93879\n",
      "Epoch 26/32\n",
      "2038140/2038140 [==============================] - 610s 300us/step - loss: 0.1757 - acc: 0.9061 - val_loss: 0.1958 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.93879\n",
      "Epoch 27/32\n",
      "2038140/2038140 [==============================] - 610s 299us/step - loss: 0.1757 - acc: 0.9061 - val_loss: 0.2115 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.93879\n",
      "Epoch 28/32\n",
      "2038140/2038140 [==============================] - 610s 299us/step - loss: 0.1771 - acc: 0.9059 - val_loss: 0.1979 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.93879\n",
      "Epoch 29/32\n",
      "2038140/2038140 [==============================] - 610s 299us/step - loss: 0.1761 - acc: 0.9059 - val_loss: 0.1956 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.93879\n",
      "Epoch 30/32\n",
      "2038140/2038140 [==============================] - 611s 300us/step - loss: 0.1759 - acc: 0.9061 - val_loss: 0.2071 - val_acc: 0.9370\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.93879\n",
      "Epoch 31/32\n",
      "2038140/2038140 [==============================] - 610s 299us/step - loss: 0.1763 - acc: 0.9060 - val_loss: 0.2025 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.93879\n",
      "Epoch 32/32\n",
      "2038140/2038140 [==============================] - 611s 300us/step - loss: 0.1762 - acc: 0.9060 - val_loss: 0.2018 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.93879\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
      "[0.8978681542949722, 0.9044403230365927, 0.9051090700337413, 0.905380886494666, 0.9055383830320034, 0.9058342410192333, 0.9058327690914004, 0.9058950808041768, 0.9059083281799396, 0.9061011510478486, 0.9059941907814403, 0.906046198981957, 0.9061850510729396, 0.9060054755771672, 0.9061987890913134, 0.9061801446405133, 0.906329300241299, 0.9062056580952362, 0.9062375499203954, 0.9061453089546584, 0.9060270638867913, 0.9061722943442329, 0.9061840697893554, 0.9060766188777627, 0.9059740743971925, 0.9061477621719244, 0.9061129264901636, 0.9058779082868245, 0.9059465983655919, 0.9061340241598673, 0.9059981159275919, 0.9059770182615146]\n",
      "[0.19974799721589967, 0.17894697765058334, 0.17697424766005665, 0.17621359612224616, 0.17592165720006933, 0.17557482864834448, 0.1755174358926787, 0.17548069719689463, 0.17533759591013426, 0.17526000702512268, 0.1752321166692699, 0.17520409160201855, 0.1753643948191199, 0.17532234423994517, 0.1752551801093353, 0.17523250860319206, 0.17550544775041643, 0.17538562276533295, 0.175435792499939, 0.1755421219298036, 0.17575818351194258, 0.17564397665396292, 0.17555775941073323, 0.1759315544579562, 0.1759479767487288, 0.17573193032065856, 0.1757397728287438, 0.17705802758297576, 0.17606929238282726, 0.17590345368876437, 0.1762966645188637, 0.1762071064565552]\n",
      "[0.21499351039640707, 0.20379296457726426, 0.21003488516319055, 0.19874910560532696, 0.19757041901410557, 0.19745442405254884, 0.19830378313520652, 0.1990350392990648, 0.20125702470001436, 0.19755098010071762, 0.20524118047009865, 0.19642310171995675, 0.19799081388478312, 0.20260354432286512, 0.2003542710417079, 0.20856657694940653, 0.19462513527816064, 0.2031064276432892, 0.20355806871373505, 0.20015391899820753, 0.198545174967492, 0.2190671226150375, 0.2008253889392124, 0.20209025021609217, 0.19383045622351355, 0.19577646694092388, 0.21152811851232367, 0.19785404088987138, 0.1956282039223696, 0.207140393631098, 0.20252767747802217, 0.2017975451330788]\n",
      "[0.9368453590080088, 0.9373575907487136, 0.9386734964274206, 0.9382495805040788, 0.9385940121917941, 0.9381171067780344, 0.9373973328665268, 0.9378124172081325, 0.9369645853614487, 0.9386602490548162, 0.9378212487898687, 0.9337587211911759, 0.9382539962949469, 0.9374856486838897, 0.9378654066985502, 0.9378742382802865, 0.938289322621892, 0.9373531749578454, 0.9382319173406062, 0.9373752539121861, 0.9378124172081325, 0.9352071005959272, 0.9387927227808606, 0.9364302746664033, 0.936668727373283, 0.9376711119003518, 0.9382760752492876, 0.9373355117943728, 0.9377770908811873, 0.9370264064336027, 0.9381436015232433, 0.9374503223569446]\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226460/226460 [==============================] - 32s 141us/step\n",
      "Test loss: 0.2017975448858264\n",
      "Test accuracy: 0.9374503223569446\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumed model's weights from model/net-cnn-best.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LDH\\Anaconda3\\lib\\site-packages\\keras\\activations.py:197: UserWarning: Do not pass a layer instance (such as Activation) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226460/226460 [==============================] - 32s 140us/step\n",
      "Test loss: 0.2017975448858264\n",
      "Test accuracy: 0.9374503223569446\n"
     ]
    }
   ],
   "source": [
    "# test to load weights\n",
    "model1 = buildModel()\n",
    "train(model1, True, 'output/net-cnn-best_final.hdf5')\n",
    "# Eval\n",
    "score = model1.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LDH\\Anaconda3\\lib\\site-packages\\keras\\activations.py:197: UserWarning: Do not pass a layer instance (such as Activation) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumed model's weights from model/net-cnn-best.hdf5\n"
     ]
    }
   ],
   "source": [
    "# test to load weights\n",
    "model1 = buildModel()\n",
    "train(model1, True, 'output/net-cnn-best_callback.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LDH\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "y_train_path = 'tmp/y_train/y_train_raw'\n",
    "    \n",
    "y_train0 = pd.read_csv(y_train_path, dtype=np.uint8, sep=',', header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def k_fold_evaluate(X, y):\n",
    "    acc_sum = 0.0\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=2)\n",
    "    for fold_index, (train_index,test_index) in enumerate(skf.split(X,y)): \n",
    "        print('---------------------------------------------')\n",
    "        print('Fold #{}'.format(fold_index))    \n",
    "        \n",
    "        X_test = X[test_index]\n",
    "        Y_test = y.values[test_index]\n",
    "        print(X_test.shape, Y_test.shape)\n",
    "        \n",
    "        # convert class vectors to binary class matrices\n",
    "        Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "        \n",
    "        # Eval\n",
    "        score = model1.evaluate(X_test, Y_test, verbose=1)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        acc_sum = acc_sum + score[1]\n",
    "    \n",
    "    print('average acc is ', (acc_sum/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Fold #0\n",
      "(407640, 64, 32, 1) (407640, 1)\n",
      "407640/407640 [==============================] - 47s 116us/step\n",
      "Test loss: 0.17175926537593955\n",
      "Test accuracy: 0.9073324502011579\n",
      "---------------------------------------------\n",
      "Fold #1\n",
      "(407625, 64, 32, 1) (407625, 1)\n",
      "407625/407625 [==============================] - 48s 118us/step\n",
      "Test loss: 0.17350797651907346\n",
      "Test accuracy: 0.9068531125421649\n",
      "---------------------------------------------\n",
      "Fold #2\n",
      "(407625, 64, 32, 1) (407625, 1)\n",
      "407625/407625 [==============================] - 47s 116us/step\n",
      "Test loss: 0.1709029697328806\n",
      "Test accuracy: 0.9079619748543392\n",
      "---------------------------------------------\n",
      "Fold #3\n",
      "(407625, 64, 32, 1) (407625, 1)\n",
      "407625/407625 [==============================] - 48s 117us/step\n",
      "Test loss: 0.17120876776003893\n",
      "Test accuracy: 0.907903097209445\n",
      "---------------------------------------------\n",
      "Fold #4\n",
      "(407625, 64, 32, 1) (407625, 1)\n",
      "407625/407625 [==============================] - 47s 115us/step\n",
      "Test loss: 0.17236659888205186\n",
      "Test accuracy: 0.9072284575283656\n",
      "average acc is  0.9074558184670944\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f0847bc1ce22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk_fold_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-3ae4bf5d05c4>\u001b[0m in \u001b[0;36mk_fold_evaluate\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'average acc is '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0macc_sum\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "k_fold_evaluate(x_train, y_train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(566149, 15)\n",
      "566149/566149 [==============================] - 78s 138us/step\n",
      "Test loss: 0.19959246909274006\n",
      "Test accuracy: 0.9393799158879722\n"
     ]
    }
   ],
   "source": [
    "x_test1, y_test1 = get_test_data()\n",
    "x_test1 = x_test1.values.reshape((x_test1.shape[0], img_rows, img_cols, 1))\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_test1 = keras.utils.to_categorical(y_test1, num_classes)\n",
    "\n",
    "print(y_test1.shape)\n",
    "\n",
    "# Eval\n",
    "score = model1.evaluate(x_test1, y_test1, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_losses = [0.21499351039640707, 0.20379296457726426, 0.21003488516319055, 0.19874910560532696, 0.19757041901410557, 0.19745442405254884, 0.19830378313520652, 0.1990350392990648, 0.20125702470001436, 0.19755098010071762, 0.20524118047009865, 0.19642310171995675, 0.19799081388478312, 0.20260354432286512, 0.2003542710417079, 0.20856657694940653, 0.19462513527816064, 0.2031064276432892, 0.20355806871373505, 0.20015391899820753, 0.198545174967492, 0.2190671226150375, 0.2008253889392124, 0.20209025021609217, 0.19383045622351355, 0.19577646694092388, 0.21152811851232367, 0.19785404088987138, 0.1956282039223696, 0.207140393631098, 0.20252767747802217, 0.2017975451330788]\n",
    "\n",
    "val_accs = [0.9368453590080088, 0.9373575907487136, 0.9386734964274206, 0.9382495805040788, 0.9385940121917941, 0.9381171067780344, 0.9373973328665268, 0.9378124172081325, 0.9369645853614487, 0.9386602490548162, 0.9378212487898687, 0.9337587211911759, 0.9382539962949469, 0.9374856486838897, 0.9378654066985502, 0.9378742382802865, 0.938289322621892, 0.9373531749578454, 0.9382319173406062, 0.9373752539121861, 0.9378124172081325, 0.9352071005959272, 0.9387927227808606, 0.9364302746664033, 0.936668727373283, 0.9376711119003518, 0.9382760752492876, 0.9373355117943728, 0.9377770908811873, 0.9370264064336027, 0.9381436015232433, 0.9374503223569446]\n",
    "\n",
    "train_losses = [0.19974799721589967, 0.17894697765058334, 0.17697424766005665, 0.17621359612224616, 0.17592165720006933, 0.17557482864834448, 0.1755174358926787, 0.17548069719689463, 0.17533759591013426, 0.17526000702512268, 0.1752321166692699, 0.17520409160201855, 0.1753643948191199, 0.17532234423994517, 0.1752551801093353, 0.17523250860319206, 0.17550544775041643, 0.17538562276533295, 0.175435792499939, 0.1755421219298036, 0.17575818351194258, 0.17564397665396292, 0.17555775941073323, 0.1759315544579562, 0.1759479767487288, 0.17573193032065856, 0.1757397728287438, 0.17705802758297576, 0.17606929238282726, 0.17590345368876437, 0.1762966645188637, 0.1762071064565552]\n",
    "\n",
    "training_accs = [0.8978681542949722, 0.9044403230365927, 0.9051090700337413, 0.905380886494666, 0.9055383830320034, 0.9058342410192333, 0.9058327690914004, 0.9058950808041768, 0.9059083281799396, 0.9061011510478486, 0.9059941907814403, 0.906046198981957, 0.9061850510729396, 0.9060054755771672, 0.9061987890913134, 0.9061801446405133, 0.906329300241299, 0.9062056580952362, 0.9062375499203954, 0.9061453089546584, 0.9060270638867913, 0.9061722943442329, 0.9061840697893554, 0.9060766188777627, 0.9059740743971925, 0.9061477621719244, 0.9061129264901636, 0.9058779082868245, 0.9059465983655919, 0.9061340241598673, 0.9059981159275919, 0.9059770182615146]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDF+YYBiGYRi+MMEwDMMwfPH/7C8k2wWDX74AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ed21768ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('losses')\n",
    "steps = [i for i in range(32)]\n",
    "plt.plot(steps, val_losses, color='blue', label='validation loss')\n",
    "plt.plot(steps, train_losses,  color='red', label='training loss')\n",
    "plt.legend() # æ˜¾ç¤ºå›¾ä¾‹\n",
    "\n",
    "plt.xlabel('epoch times')\n",
    "plt.ylabel('loss value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLEoYIiISixKGiIjE8v8DI20mXoYuzjcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ed22c1cb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Accuracy')\n",
    "steps = [i for i in range(32)]\n",
    "plt.plot(steps, val_accs, color='blue', label='validation accuracy')\n",
    "plt.plot(steps, training_accs, color='red', label='train accuracy')\n",
    "plt.legend() # æ˜¾ç¤ºå›¾ä¾‹\n",
    "\n",
    "plt.xlabel('epoch times')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
